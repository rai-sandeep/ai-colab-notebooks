{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rai-sandeep/ai-colab-notebooks/blob/main/Training-Stable-V2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzGa3YSCgl4C"
      },
      "source": [
        "# Install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "7wgbsa4U2TBk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8e78dad-17d6-49d5-cba7-59d8fdae1f16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: HF_TOKEN=<ENTER-HUGGINGFACE-TOKEN-HERE>\n"
          ]
        }
      ],
      "source": [
        "# https://stackoverflow.com/questions/56081324/why-are-google-colab-shell-commands-not-working\n",
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding\n",
        "\n",
        "model_id = \"vilsonrodrigues/falcon-7b-instruct-sharded\"\n",
        "trained_model_id = \"falcon-7b-instruct-sharded-trained-v1\"\n",
        "ds_id = \"rai-sandeep/dataset_format_v1\"\n",
        "example_ques = \"Generate a White Paper ABSTRACT on Modernizing Enterprise Systems.\"\n",
        "#example_ques2 = \"Generate a White Paper MAINCONTENT on Bitcoin Mining.\"\n",
        "max_tok = 200\n",
        "\n",
        "save_trained_model=False\n",
        "%env HF_TOKEN=<ENTER-HUGGINGFACE-TOKEN-HERE>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGeTgx1Hgljb",
        "outputId": "8db79eff-4192-44c2-985c-47e5fe44d452"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q -U bitsandbytes\n",
        "!pip install -q -U git+https://github.com/huggingface/transformers.git\n",
        "!pip install -q -U git+https://github.com/huggingface/peft.git\n",
        "!pip install -q -U git+https://github.com/huggingface/accelerate.git\n",
        "!pip install -q -U einops\n",
        "!pip install -q -U safetensors\n",
        "!pip install -q -U torch\n",
        "!pip install -q -U xformers\n",
        "!pip install -q -U datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1zodOgcgqnO"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "v_r4SL_KmHGs"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline\n",
        "import transformers\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch\n",
        "from transformers import AutoTokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Quantized Model"
      ],
      "metadata": {
        "id": "alLhGWu9Ngvg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "b8ba8a7e08194132b765d4c80e18475c",
            "f24557f3386b4dc88b89f642ce581c8a",
            "1a905643a6334287bdcab47f30390f1f",
            "7602f1821bb241f0b10c9e05480ea84d",
            "e528bbed327b46ee8878c9b1c4941372",
            "807afde684a6425aad4f05db706efc7b",
            "2a767b8a49a94e9782c3f550eab3d33f",
            "ed1d4df924444644ab5c167b0d5ad8bc",
            "10faa0b76e6f4fd3a9fdb64955744e6e",
            "690381e5700f4a909e5b13cb87e86c94",
            "7b4615dac78243389cd534dc1c5695bb"
          ]
        },
        "id": "tz4eBuxZHi7F",
        "outputId": "cf906bef-7b86-4cdc-c7fa-26566d424c50"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/15 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b8ba8a7e08194132b765d4c80e18475c"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map={\"\":0}, trust_remote_code=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import prepare_model_for_kbit_training\n",
        "\n",
        "model.gradient_checkpointing_enable()\n",
        "model = prepare_model_for_kbit_training(model)"
      ],
      "metadata": {
        "id": "Hd22_v_mkbZy"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_trainable_parameters(model):\n",
        "    \"\"\"\n",
        "    Prints the number of trainable parameters in the model.\n",
        "    \"\"\"\n",
        "    trainable_params = 0\n",
        "    all_param = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_param += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "    print(\n",
        "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
        "    )"
      ],
      "metadata": {
        "id": "HOhd6empkd0_"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"query_key_value\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, config)\n",
        "print_trainable_parameters(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qjN7qOkkgKI",
        "outputId": "3f0c1ea3-3471-49e7-e0a8-498d8ac8da6a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 4718592 || all params: 3613463424 || trainable%: 0.13058363808693696\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare Data"
      ],
      "metadata": {
        "id": "mxDuoyQvQfD2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194,
          "referenced_widgets": [
            "35215ebeec2d4953b0a597627dd808d7",
            "1a9a37de35744e988ce2e80e11c55913",
            "5b1abe1a3a454ff3a8fcf4ffedfda269",
            "b41cbe7ea9334c468f6caecd736b8e2a",
            "4f9f931dc2c94c5099826a0ca6ee8d10",
            "cb70ceb063aa46fcb2d2a088e99c596b",
            "5415ef998ce143499ee02fc47d760864",
            "d157e365651945c099452a8ba4bf38a5",
            "9c3adc02be6c4c36bd24ee07a14d24f4",
            "bbd875da3cd3431fabf599fc892e9a7a",
            "456212e7dcbc4c26968d1bb1e112e431"
          ]
        },
        "id": "UZbrRk4J3qVH",
        "outputId": "47f75cad-bc3d-4b3d-99f9-2f6729f62bbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset parquet (/root/.cache/huggingface/datasets/rai-sandeep___parquet/rai-sandeep--dataset_format_v1-f2d2fe6009d0ed8b/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "35215ebeec2d4953b0a597627dd808d7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This white paper examines [Topic/Issue] and provides insights into [Key Points/Findings]. It explores [Main Theme/Techniques] and highlights [Benefits/Challenges]. The analysis presented here acts as a guideline for [Target Audience] to make strategic and informed decisions on [Action/Implementation]. By delving into [Key Concepts/Approaches], this paper aims to assist [Target Audience] in [Objective/Goal]. The findings discussed herein contribute to the ongoing conversation surrounding [Topic/Issue] and offer practical recommendations for [Action/Implementation].']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "data = load_dataset(ds_id)\n",
        "\n",
        "ds_len=len(data['train'])\n",
        "rows_sel=data['train'].select(range(1))\n",
        "rows_sel['template']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7Pbb_6H6C2t",
        "outputId": "94f8b85c-e4bb-495b-fa40-2dea80a05d78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/rai-sandeep___parquet/rai-sandeep--dataset_format_v1-f2d2fe6009d0ed8b/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7/cache-b96d48d3112cde67.arrow\n"
          ]
        }
      ],
      "source": [
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# prompt_template = \"### Instruction: {prompt}\\n### Response:\"\n",
        "\n",
        "train_dataset = data['train'].select(range(ds_len)).map(lambda x: {\"input_text\": \"Format for \" + x['doctype'] + \" \" + x['section'] + \":\\n\" + x['template']})\n",
        "\n",
        "# Tokenize the datasets\n",
        "train_encodings = tokenizer(train_dataset['input_text'], max_length=256, truncation=True, padding=True, return_tensors='pt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  class TextDataset(Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item[\"labels\"] = item[\"input_ids\"].clone()\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings[\"input_ids\"])\n"
      ],
      "metadata": {
        "id": "whNBQA9m0EPb"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the encodings to PyTorch datasets\n",
        "train_dataset = TextDataset(train_encodings)"
      ],
      "metadata": {
        "id": "hrNxx33K0H9p"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example Before Fine Tuning"
      ],
      "metadata": {
        "id": "RWGTyUHhSZx-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(when_id):\n",
        "\n",
        "  doc_type = \"White Paper\"\n",
        "  topic = \"Infosys Watch Tower\"\n",
        "  keywords = \"Fire and smoke detection, Birds monitoring, Unattended cabin baggage detection, Vegetation monitoring\"\n",
        "  content_to_use = \"Infosys Watch Tower enables real-time monitoring of situations, which is an important aspect of operations, specifically in the aviation industry. The need for monitoring increases exponentially at airports where crowd management and security are amplified. Infosys Watch Tower mitigates security threats and tracks cargo, thereby ensuring smooth operations. The platform onboards different sensors such as camera, drone, and light detection and ranging (LiDAR) to detect and gather information about incidents, while streamlining business flows at airports and on runways. Infosys Watch Tower uses drones to inspect aircraft and sonar for Non-destructive Testing (NDT) for identifying and detecting material damage. It is scalable to support thousands of sensors along with real-time processed feeds based on sensor configuration and monitoring plans. Infosys Watch Tower leverages cutting-edge 5G technology for aviation enterprises to create low-code / no-code AI workflows for installed sensors. These workflows are easily configurable and can be deployed across various edges. The platform can be extended to multiple AI domains such as computer vision, and across multiple sub-domains such as retail, facility management, and security, which are ancillary businesses in aviation. The platform offers a unified view of inferences, reports, monitoring plans and alerts via reports and analytics. It provides management with 360-degree visibility into different incidents and events. Apart from serving as a smart assistant for security personnel and a guide to the operations manager, the data collected as part of 24x7 monitoring enhances overall security and maintenance.\"\n",
        "\n",
        "  doc_content=\"\"\n",
        "  doc_parts=[\"Abstract\",\"Introduction\",\"Problem Statement\",\"Methodology\",\"Findings and Analysis\",\"Recommendations\",\"Conclusion\"]\n",
        "\n",
        "  for doc_part in doc_parts:\n",
        "    prompt = f\"Generate a {doc_type} {doc_part} on {topic}.\"\n",
        "    if keywords.strip() != \"\":\n",
        "      prompt += f\"\\nInclude the following keywords: {keywords}.\"\n",
        "    if content_to_use.strip() != \"\":\n",
        "      prompt += f\"\\nHere is some context about {topic}: {content_to_use}.\\n\"\n",
        "\n",
        "    encoding = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda:0\")\n",
        "    output = model.generate(input_ids=encoding.input_ids, attention_mask=encoding.attention_mask, max_new_tokens=max_tok, do_sample=True, temperature=0.000001, eos_token_id=tokenizer.eos_token_id, top_k = 0)\n",
        "\n",
        "    temp_content=tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    temp_content=temp_content.replace(prompt, \"\")\n",
        "    doc_content+=f\"\\n## {doc_part}  \\n{temp_content}  \\n\"\n",
        "\n",
        "  print(doc_content)\n",
        "\n",
        "  f = open(topic.replace(\" \", \"-\")+\"-\"+when_id+\".md\", \"w\")\n",
        "  f.write(doc_content)\n",
        "  f.close()"
      ],
      "metadata": {
        "id": "xx4mKCzFPEM7"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate(\"before\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pRFK3thQ1XV",
        "outputId": "ec187c13-1b9e-4b22-a786-60f45db087a9"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1264: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "## Abstract  \n",
            "\n",
            "Modernizing enterprise systems is a critical challenge for businesses today. This white paper explores the current state of enterprise systems and the opportunities for improvement. It examines the drivers for change, the challenges and barriers to modernization, and the benefits that can be achieved. The paper also provides practical guidance on how to approach modernization, including strategies for successful implementation and ongoing maintenance.  \n",
            "\n",
            "## Introduction  \n",
            "\n",
            "In today's fast-paced digital world, businesses need to keep up with the latest trends and technologies to remain competitive. This white paper explores the challenges and opportunities that modern enterprise systems face, and how businesses can leverage emerging technologies to streamline their operations and drive innovation.  \n",
            "\n",
            "## Problem Statement  \n",
            "\n",
            "Modernizing enterprise systems is a complex challenge that organizations face as they strive to keep pace with rapidly evolving technology landscapes. The proliferation of digital channels, the rise of mobile devices, and the increasing adoption of cloud-based services have placed unprecedented demands on legacy systems, leading to inefficiencies, siloed data, and a lack of agility. To remain competitive, enterprises must transform their systems to be more flexible, scalable, and adaptable to changing market conditions. This white paper explores the challenges and opportunities associated with modernizing enterprise systems and provides guidance on how organizations can overcome these challenges and achieve success.  \n",
            "\n",
            "## Methodology  \n",
            "\n",
            "To modernize enterprise systems, organizations should follow a comprehensive methodology that includes the following steps: 1. Assess current systems and processes to identify areas for improvement. 2. Develop a strategy to integrate new systems and processes. 3. Implement new systems and processes, ensuring proper training and communication. 4. Monitor and maintain the systems and processes for ongoing optimization. 5. Continuously evaluate and update the strategy as needed to stay competitive in the market.  \n",
            "\n",
            "## Findings and Analysis  \n",
            "\n",
            "Modernizing enterprise systems is a critical challenge for businesses today. As companies strive to keep up with the latest technology trends, they need to ensure their systems are efficient, scalable, and secure. This white paper examines the current state of enterprise systems and provides findings and analysis on the best practices for modernizing them. The paper covers topics such as cloud computing, data analytics, and automation, and offers insights on how businesses can leverage these technologies to drive innovation and improve their bottom line.  \n",
            "\n",
            "## Recommendations  \n",
            "\n",
            "To modernize enterprise systems, organizations should consider implementing a comprehensive strategy that includes the following recommendations: 1) Assess current systems and processes to identify areas for improvement; 2) Establish a clear vision for modernization and communicate it to all stakeholders; 3) Develop a phased modernization plan that prioritizes critical systems and processes; 4) Invest in training and education to ensure employees are prepared for the changes; 5) Implement automation and digital transformation strategies to increase efficiency and productivity; 6) Implement data analytics to gain valuable insights; 7) Choose flexible, scalable systems that can adapt to evolving business needs; 8) Foster a culture of innovation and continuous improvement.  \n",
            "\n",
            "## Conclusion  \n",
            "\n",
            "Modernizing enterprise systems is essential for businesses to remain competitive and adapt to changing market conditions. This white paper concludes that implementing a unified platform for data and applications can help organizations streamline processes, reduce costs, and increase customer satisfaction. The paper also emphasizes the importance of embracing digital technologies, such as artificial intelligence and machine learning, to further enhance business operations.  \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "J53zPp1qSdZp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iDniJ-bq4nxD",
        "outputId": "753a2f04-be6d-4276-b79e-7e57a2f8a5c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-30-bd500a371ea7>:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [50/50 04:29, Epoch 50/50]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.474100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.474100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.472500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.467900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.458500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.445400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.429000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.410000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.388900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.368200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.349200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.330200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.311200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.290200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.267600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.244000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.221000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.199000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.179100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.161500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.148200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.134400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.119300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.103900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.090400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.080200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.072600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.064000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.053800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.044500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.037200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.032000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.029800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.028700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.026800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.024100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.022000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.019400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.017400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.016100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.014700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.014200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.013400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.012900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.012600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.012300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.011900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.011800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.011700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.011500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=50, training_loss=0.16466441610828042, metrics={'train_runtime': 274.5782, 'train_samples_per_second': 1.275, 'train_steps_per_second': 0.182, 'total_flos': 1741947043200000.0, 'train_loss': 0.16466441610828042, 'epoch': 50.0})"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "trainer = transformers.Trainer(\n",
        "    model=model,\n",
        "    train_dataset=train_dataset,\n",
        "    # eval_dataset=val_dataset,\n",
        "    args=transformers.TrainingArguments(\n",
        "        num_train_epochs=50,\n",
        "        per_device_train_batch_size=16,\n",
        "        gradient_accumulation_steps=4,\n",
        "        warmup_ratio=0.05,\n",
        "        # max_steps=100,\n",
        "        learning_rate=2e-4,\n",
        "        fp16=True,\n",
        "        logging_steps=1,\n",
        "        output_dir=\"outputs\",\n",
        "        optim=\"paged_adamw_8bit\",\n",
        "        lr_scheduler_type='cosine',\n",
        "    ),\n",
        "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
        ")\n",
        "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n",
        "\n",
        "#import gc\n",
        "#del train_encodings, data\n",
        "#gc.collect()\n",
        "#torch.cuda.empty_cache()\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example After Fine Tuning"
      ],
      "metadata": {
        "id": "KWXT-FNfSlpk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.config.use_cache = True\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9vrd1FXSz8W",
        "outputId": "98e0e917-3f06-4951-bd5f-a962498e81fe"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PeftModelForCausalLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): RWForCausalLM(\n",
              "      (transformer): RWModel(\n",
              "        (word_embeddings): Embedding(65024, 4544)\n",
              "        (h): ModuleList(\n",
              "          (0-31): 32 x DecoderLayer(\n",
              "            (input_layernorm): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n",
              "            (self_attention): Attention(\n",
              "              (maybe_rotary): RotaryEmbedding()\n",
              "              (query_key_value): Linear4bit(\n",
              "                in_features=4544, out_features=4672, bias=False\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4544, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=4672, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
              "              (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (mlp): MLP(\n",
              "              (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
              "              (act): GELU(approximate='none')\n",
              "              (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (ln_f): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (lm_head): Linear(in_features=4544, out_features=65024, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate(\"after\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MezO1msTSnEs",
        "outputId": "76e9a787-7637-4041-a701-3be448dca38f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "## Abstract  \n",
            "\n",
            "In this white paper, we explore the challenges and opportunities associated with modernizing enterprise systems. We highlight the benefits such as increased efficiency, improved decision-making, and enhanced competitiveness. We propose practical strategies and approaches for implementing modernized systems, including the adoption of cutting-edge technologies, the implementation of innovative processes, and the implementation of data-driven analytics. By focusing on the advantages and leveraging the latest technologies, organizations can successfully modernize their systems and achieve their business objectives.  \n",
            "\n",
            "## Introduction  \n",
            "\n",
            "In today's fast-paced digital landscape, enterprises across industries are facing challenges in effectively and efficiently managing their operations. This white paper explores the modernizing trends of enterprise systems and the potential benefits in streamlining processes, improving decision-making, and enhancing overall performance. By embracing cutting-edge technologies like cloud computing, artificial intelligence, and automation, organizations can modernize their systems and achieve a competitive advantage in the market. The paper delves into the key drivers, challenges, and opportunities in this transformation, providing practical recommendations and case studies to help businesses successfully navigate the changes.  \n",
            "\n",
            "## Problem Statement  \n",
            "\n",
            "How can organizations modernize and optimize their enterprise systems to achieve efficiency, agility, and scalability in the digital age?  \n",
            "\n",
            "## Methodology  \n",
            "\n",
            "Modernizing enterprise systems involves a comprehensive approach that leverages cutting-edge technologies, such as cloud computing, artificial intelligence, and automation, to streamline processes and enhance efficiency. The key components of a successful modernization strategy include: 1. Assessment of the current system landscape and identification of improvement opportunities; 2. Development of a phased implementation plan that addresses these opportunities; 3. Training and education of employees to ensure they are equipped to handle the changes; 4. Ongoing monitoring and evaluation to ensure the system's continued effectiveness and evolving needs are met. By implementing modern technologies and a structured approach, organizations can achieve significant improvements in operational efficiency, customer satisfaction, and overall competitiveness. This white paper explores the various methodologies, best practices, and benefits of modernizing enterprise systems, providing a comprehensive guide for organizations seeking to enhance their operational performance and stay competitive in the evolving digital landscape.  \n",
            "\n",
            "## Findings and Analysis  \n",
            "\n",
            "Modernizing enterprise systems has become a critical priority for businesses of all sizes as they strive to streamline processes, enhance productivity, and keep up with evolving technology trends. According to our analysis, implementing digital technologies such as automation, artificial intelligence, and cloud computing have been shown to significantly improve operational efficiency and reduce overall costs. However, there are also challenges that come with modernizing systems, such as resistance to change and potential disruptions to ongoing operations. Our findings suggest that businesses should prioritize strategic planning and careful implementation of digital technologies to successfully modernize their systems and achieve long-term success.  \n",
            "\n",
            "## Recommendations  \n",
            "\n",
            "Implementing modern enterprise systems can bring numerous benefits to businesses, such as increased efficiency, improved decision-making, and increased competitiveness. To successfully modernize your systems, consider the following recommendations: 1. Perform a thorough analysis of your current processes and identify areas for improvement. 2. Invest in cutting-edge technologies that can streamline your operations. 3. Develop a comprehensive strategy for implementation, including training and communication. 4. Establish clear guidelines and standards for employees to follow. 5. Implement agile methodologies to facilitate continuous improvement and adapt to evolving business needs. By following these recommendations, organizations can modernize their systems and achieve a competitive advantage in the market.  \n",
            "\n",
            "## Conclusion  \n",
            "\n",
            "In conclusion, modernizing enterprise systems can be a complex but rewarding process. Organizations that embrace digital technologies and innovative methodologies can experience increased efficiency, improved decision-making, and a competitive advantage in the market. However, they also need to carefully consider the potential challenges and implement effective strategies to ensure a successful transformation. By leveraging cutting-edge technologies and leveraging the expertise of their employees, organizations can modernize their systems and achieve sustainable success.  \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save the Model"
      ],
      "metadata": {
        "id": "w60z4hyJzdaW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if (save_trained_model):\n",
        "  trainer.save_model(trained_model_id)\n",
        "  !huggingface-cli login --token $HF_TOKEN\n",
        "  model.push_to_hub(\"rai-sandeep/\"+trained_model_id, create_pr=1)"
      ],
      "metadata": {
        "id": "SDRHSSnZznmH"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8bK8VfO33_WI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prompt_and_generate():\n",
        "\n",
        "  doc_type = input(\"What type of document do you want to generate? (Enter White Paper or Press Release)\\n\")\n",
        "  topic = input(f\"On what topic do you want to generate the {doc_type}?\\n\")\n",
        "  keywords = input(f\"Enter any keywords that should be part of the {doc_type} in comma separated format. If none, press Enter.\\n\")\n",
        "  content_to_use = input(f\"Enter any content that should be used for the {doc_type}. If none, press Enter.\\n\")\n",
        "\n",
        "  doc_content=\"\"\n",
        "  doc_parts=[\"Abstract\",\"Introduction\",\"Problem Statement\",\"Methodology\",\"Findings and Analysis\",\"Recommendations\",\"Conclusion\"]\n",
        "\n",
        "  for doc_part in doc_parts:\n",
        "    prompt = f\"Generate a {doc_type} {doc_part} on {topic}.\"\n",
        "    if keywords.strip() != \"\":\n",
        "      prompt += f\"\\nInclude the following keywords: {keywords}.\"\n",
        "    if content_to_use.strip() != \"\":\n",
        "      prompt += f\"\\nHere is some context about {topic}: {content_to_use}.\\n\"\n",
        "\n",
        "    encoding = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda:0\")\n",
        "    output = model.generate(input_ids=encoding.input_ids, attention_mask=encoding.attention_mask, max_new_tokens=max_tok, do_sample=True, temperature=0.000001, eos_token_id=tokenizer.eos_token_id, top_k = 0)\n",
        "\n",
        "    temp_content=tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    temp_content=temp_content.replace(prompt, \"\")\n",
        "    doc_content+=f\"\\n## {doc_part}  \\n{temp_content}  \\n\"\n",
        "\n",
        "  print(doc_content)\n",
        "\n",
        "  f = open(topic.replace(\" \", \"-\")+\".md\", \"w\")\n",
        "  f.write(doc_content)\n",
        "  f.close()"
      ],
      "metadata": {
        "id": "rFjXfYivrnGD"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prompt_and_generate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79gmk3y1v6WK",
        "outputId": "5be85547-3a40-4945-922c-76b23a2897cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What type of document do you want to generate? (Enter White Paper or Press Release)\n",
            "White Paper\n",
            "On what topic do you want to generate the White Paper?\n",
            "Smarter way to build system resilience\n",
            "Enter any keywords that should be part of the White Paper in comma separated format. If none, press Enter.\n",
            "Infrastructure, chaos, regression\n",
            "Enter any content that should be used for the White Paper. If none, press Enter.\n",
            "How Chaos Engineering is Different from Traditional Testing Practices • Performance testing – It baselines application performance under a defined load in favorable environmental conditions. The main objective is to check how the system performs when the application is up and running without any severe functional defects in an environment comparable to the production environment. The potential disruptors uncovered during the performance tests are due to certain load conditions on the application. • Disaster recovery testing – This process ensures that an organization can restore its data and applications to continue operations even after critical IT failure or complete service disruption. • Chaos testing – During the chaos test, the application under normal load is subjected to known failures outside the prescribed boundaries with minimum blast radius to check if the system behaves as expected. Any deviation from expectations is noted as an observation and mitigation steps are prepared to rectify the deviation. Quality assurance engineers find chaos testing to be more effective than performance and disaster recovery testing in unearthing latent bugs and identifying unanticipated system weaknesses.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b8ba8a7e08194132b765d4c80e18475c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f24557f3386b4dc88b89f642ce581c8a",
              "IPY_MODEL_1a905643a6334287bdcab47f30390f1f",
              "IPY_MODEL_7602f1821bb241f0b10c9e05480ea84d"
            ],
            "layout": "IPY_MODEL_e528bbed327b46ee8878c9b1c4941372"
          }
        },
        "f24557f3386b4dc88b89f642ce581c8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_807afde684a6425aad4f05db706efc7b",
            "placeholder": "​",
            "style": "IPY_MODEL_2a767b8a49a94e9782c3f550eab3d33f",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "1a905643a6334287bdcab47f30390f1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed1d4df924444644ab5c167b0d5ad8bc",
            "max": 15,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_10faa0b76e6f4fd3a9fdb64955744e6e",
            "value": 15
          }
        },
        "7602f1821bb241f0b10c9e05480ea84d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_690381e5700f4a909e5b13cb87e86c94",
            "placeholder": "​",
            "style": "IPY_MODEL_7b4615dac78243389cd534dc1c5695bb",
            "value": " 15/15 [02:24&lt;00:00,  8.15s/it]"
          }
        },
        "e528bbed327b46ee8878c9b1c4941372": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "807afde684a6425aad4f05db706efc7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a767b8a49a94e9782c3f550eab3d33f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed1d4df924444644ab5c167b0d5ad8bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10faa0b76e6f4fd3a9fdb64955744e6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "690381e5700f4a909e5b13cb87e86c94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b4615dac78243389cd534dc1c5695bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "35215ebeec2d4953b0a597627dd808d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1a9a37de35744e988ce2e80e11c55913",
              "IPY_MODEL_5b1abe1a3a454ff3a8fcf4ffedfda269",
              "IPY_MODEL_b41cbe7ea9334c468f6caecd736b8e2a"
            ],
            "layout": "IPY_MODEL_4f9f931dc2c94c5099826a0ca6ee8d10"
          }
        },
        "1a9a37de35744e988ce2e80e11c55913": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb70ceb063aa46fcb2d2a088e99c596b",
            "placeholder": "​",
            "style": "IPY_MODEL_5415ef998ce143499ee02fc47d760864",
            "value": "100%"
          }
        },
        "5b1abe1a3a454ff3a8fcf4ffedfda269": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d157e365651945c099452a8ba4bf38a5",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9c3adc02be6c4c36bd24ee07a14d24f4",
            "value": 1
          }
        },
        "b41cbe7ea9334c468f6caecd736b8e2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bbd875da3cd3431fabf599fc892e9a7a",
            "placeholder": "​",
            "style": "IPY_MODEL_456212e7dcbc4c26968d1bb1e112e431",
            "value": " 1/1 [00:00&lt;00:00, 13.51it/s]"
          }
        },
        "4f9f931dc2c94c5099826a0ca6ee8d10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb70ceb063aa46fcb2d2a088e99c596b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5415ef998ce143499ee02fc47d760864": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d157e365651945c099452a8ba4bf38a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c3adc02be6c4c36bd24ee07a14d24f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bbd875da3cd3431fabf599fc892e9a7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "456212e7dcbc4c26968d1bb1e112e431": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}