{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rai-sandeep/ai-colab-notebooks/blob/main/f7b-trained-V3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzGa3YSCgl4C"
      },
      "source": [
        "# Install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7wgbsa4U2TBk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1a3c7b0-c1a8-4cfa-f185-25842a9e4b67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: HF_TOKEN=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\n"
          ]
        }
      ],
      "source": [
        "# https://stackoverflow.com/questions/56081324/why-are-google-colab-shell-commands-not-working\n",
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding\n",
        "\n",
        "model_id = \"vilsonrodrigues/falcon-7b-sharded\"\n",
        "trained_model_id = \"falcon-7b-sharded-template\"\n",
        "\n",
        "#ds_id = \"rai-sandeep/dataset_template\"\n",
        "\n",
        "#ds_id = \"rai-sandeep/wp_combined_dataset\"\n",
        "\n",
        "#example_ques = \"Generate a White Paper ABSTRACT on Modernizing Enterprise Systems.\"\n",
        "#example_ques2 = \"Generate a White Paper MAINCONTENT on Bitcoin Mining.\"\n",
        "max_tok = 1000\n",
        "tempre = 0.1\n",
        "\n",
        "save_trained_model=False\n",
        "%env HF_TOKEN=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"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WGeTgx1Hgljb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5455ef1-e8d1-44cb-f7b1-87ff1e5e3d56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q -U bitsandbytes\n",
        "!pip install -q -U git+https://github.com/huggingface/transformers.git\n",
        "!pip install -q -U git+https://github.com/huggingface/peft.git\n",
        "!pip install -q -U git+https://github.com/huggingface/accelerate.git\n",
        "!pip install -q -U einops\n",
        "!pip install -q -U safetensors\n",
        "!pip install -q -U torch\n",
        "!pip install -q -U xformers\n",
        "!pip install -q -U datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1zodOgcgqnO"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "v_r4SL_KmHGs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a69dd19-96c2-4090-f10e-a24b1ff4ec13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===================================BUG REPORT===================================\n",
            "Welcome to bitsandbytes. For bug reports, please run\n",
            "\n",
            "python -m bitsandbytes\n",
            "\n",
            " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
            "================================================================================\n",
            "bin /usr/local/lib/python3.10/dist-packages/bitsandbytes/libbitsandbytes_cuda118.so\n",
            "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
            "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so.11.0\n",
            "CUDA SETUP: Highest compute capability among GPUs detected: 7.5\n",
            "CUDA SETUP: Detected CUDA version 118\n",
            "CUDA SETUP: Loading binary /usr/local/lib/python3.10/dist-packages/bitsandbytes/libbitsandbytes_cuda118.so...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: /usr/lib64-nvidia did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/sys/fs/cgroup/memory.events /var/colab/cgroup/jupyter-children/memory.events')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('8013'), PosixPath('http'), PosixPath('//172.28.0.1')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//colab.research.google.com/tun/m/cc48301118ce562b961b3c22d803539adc1e0c19/gpu-t4-s-28liqjc8yxsvc --tunnel_background_save_delay=10s --tunnel_periodic_background_save_frequency=30m0s --enable_output_coalescing=true --output_coalescing_required=true'), PosixPath('--logtostderr --listen_host=172.28.0.12 --target_host=172.28.0.12 --tunnel_background_save_url=https')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/env/python')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('module'), PosixPath('//ipykernel.pylab.backend_inline')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/usr/local/cuda/lib64/libcudart.so.11.0'), PosixPath('/usr/local/cuda/lib64/libcudart.so')}.. We'll flip a coin and try one of these, in order to fail forward.\n",
            "Either way, this might cause trouble in the future:\n",
            "If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.\n",
            "  warn(msg)\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline\n",
        "import transformers\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch\n",
        "from transformers import AutoTokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Quantized Model"
      ],
      "metadata": {
        "id": "alLhGWu9Ngvg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "tz4eBuxZHi7F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "d5165c975b6d4f858adf6a942d8ce603",
            "247b9fb9b9ef41c081a789bfdfc91d6d",
            "d4e9bf6bbb9547d7ad3c8f90681889d4",
            "f029ba63c1f84cea95ae0e67b3308896",
            "2cc11e3e6de14442a55b6a2bc6b528b7",
            "e33cb654fc984f62b9a399c43375c60a",
            "e124c9e1b256441bbde82eeea4b73b6b",
            "3e7fd6e4ac37406c8fa29b5d664d1b5b",
            "91b38304376141ac8b4b8d5229022b5c",
            "4e2a13025a2b471a9403f76a1ad6f2cb",
            "d0fc4d839e3540338e7b4e06913b7dd5"
          ]
        },
        "outputId": "da1fe684-41ae-4e47-899f-aad7173dd40e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/15 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d5165c975b6d4f858adf6a942d8ce603"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map={\"\":0}, trust_remote_code=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import prepare_model_for_kbit_training\n",
        "\n",
        "model.gradient_checkpointing_enable()\n",
        "model = prepare_model_for_kbit_training(model)"
      ],
      "metadata": {
        "id": "Hd22_v_mkbZy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_trainable_parameters(model):\n",
        "    \"\"\"\n",
        "    Prints the number of trainable parameters in the model.\n",
        "    \"\"\"\n",
        "    trainable_params = 0\n",
        "    all_param = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_param += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "    print(\n",
        "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
        "    )"
      ],
      "metadata": {
        "id": "HOhd6empkd0_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"query_key_value\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, config)\n",
        "print_trainable_parameters(model)"
      ],
      "metadata": {
        "id": "-qjN7qOkkgKI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a5f5044-b000-4faf-e951-1e76872b884c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 4718592 || all params: 3613463424 || trainable%: 0.13058363808693696\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare Data"
      ],
      "metadata": {
        "id": "mxDuoyQvQfD2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "UZbrRk4J3qVH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243,
          "referenced_widgets": [
            "b0b1208a39ad467da6b76dcd0b1fcfbf",
            "e7a6a99c066248249d0004d33e73f4fa",
            "b13770c8758c415a9f6d719065378101",
            "c50f26e480334f26841cf0bd97ad63c5",
            "8ec60d4e340e43c39880e6c8dd5ae08e",
            "cae3b9d0945e4de3a1a9668ab7b95fff",
            "944ffb5ee6a744f0840026954a0548c5",
            "351e130072564c0d87568671bdfb84bd",
            "26a5c7d1081b4da9980b8fab9d9d67f8",
            "71f322d3d5f547d0b004a9cb71a170b5",
            "2572bff465524b4c807b51b649a832a6"
          ]
        },
        "outputId": "076a0327-6871-44d0-8981-3d14d7548228"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset csv (/root/.cache/huggingface/datasets/csv/default-626f1c772f7eb197/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b0b1208a39ad467da6b76dcd0b1fcfbf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This white paper examines the role of artificial intelligence (AI) in modernizing enterprise systems. It provides insights into how AI can transform traditional manual testing processes into automated validation models that accelerate time to market. The paper discusses the existing challenges of traditional testing automation and highlights how AI and machine learning (ML) can resolve these challenges. By exploring five use-cases and solutions, it demonstrates how AI/ML can enable complete and intelligent automation with minimal human intervention, empowering testing teams to become truly agile. The findings presented in this paper contribute to the ongoing conversation surrounding the digitization and automation of enterprise systems, offering practical recommendations for organizations aiming to modernize their testing approaches through the adoption of AI technologies.']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "#data = load_dataset(ds_id)\n",
        "data = load_dataset(\"csv\", data_files=\"/content/dataset_content.csv\")\n",
        "\n",
        "ds_len=len(data['train'])\n",
        "rows_sel=data['train'].select(range(1))\n",
        "rows_sel['content']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "c7Pbb_6H6C2t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54,
          "referenced_widgets": [
            "0a2e00f23d0c429a8721e50f4264a1f4",
            "eb2cd01478ea49c58421d6f0b43e34d6",
            "2c325a83f05f49d3b7985b127ac1c288",
            "a020dadab920451e81ec7fda70fa4f06",
            "34e515b47e73438e9ef8c68390741a16",
            "19fbd49126e4460ea9b2f581e1e9ad38",
            "7ff5d3f72e8041d49bd9c493e415453f",
            "20eb1cd1d16e4376b5aa4ebe3d25b8bb",
            "b9b3e41cfd8146edb750d5843b9c1f0a",
            "1fe68941b14a4e18b4154fdaaee09e19",
            "c24dd9d0428642189829752ce5992439"
          ]
        },
        "outputId": "c0ff58e4-2dcf-46f8-fa12-278e4e2f4bf2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/23 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0a2e00f23d0c429a8721e50f4264a1f4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'doctype': 'White Paper', 'section': 'Abstract', 'contenttype': 'example', 'topic': 'Role of Artificial Intelligence (AI) in Modernizing Enterprise Systems', 'content': 'This white paper examines the role of artificial intelligence (AI) in modernizing enterprise systems. It provides insights into how AI can transform traditional manual testing processes into automated validation models that accelerate time to market. The paper discusses the existing challenges of traditional testing automation and highlights how AI and machine learning (ML) can resolve these challenges. By exploring five use-cases and solutions, it demonstrates how AI/ML can enable complete and intelligent automation with minimal human intervention, empowering testing teams to become truly agile. The findings presented in this paper contribute to the ongoing conversation surrounding the digitization and automation of enterprise systems, offering practical recommendations for organizations aiming to modernize their testing approaches through the adoption of AI technologies.', 'input_text': 'Generate Abstract for a White Paper on topic Role of Artificial Intelligence (AI) in Modernizing Enterprise Systems\\nThis white paper examines the role of artificial intelligence (AI) in modernizing enterprise systems. It provides insights into how AI can transform traditional manual testing processes into automated validation models that accelerate time to market. The paper discusses the existing challenges of traditional testing automation and highlights how AI and machine learning (ML) can resolve these challenges. By exploring five use-cases and solutions, it demonstrates how AI/ML can enable complete and intelligent automation with minimal human intervention, empowering testing teams to become truly agile. The findings presented in this paper contribute to the ongoing conversation surrounding the digitization and automation of enterprise systems, offering practical recommendations for organizations aiming to modernize their testing approaches through the adoption of AI technologies.'}\n"
          ]
        }
      ],
      "source": [
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# prompt_template = \"### Instruction: {prompt}\\n### Response:\"\n",
        "\n",
        "#train_dataset = data['train'].select(range(ds_len)).map(lambda x: {\"input_text\": \"Template for \" + x['doctype'] + \" \" + x['section'] + \":\\n\" + x['template']})\n",
        "\n",
        "#train_dataset = data['train'].select(range(ds_len)).map(lambda x: {\"input_text\": \"Use this \" + x['contenttype'] + \" to generate \" + x['section'] + \" for a \" + x['doctype'] + \": \" + x['content']})\n",
        "\n",
        "train_dataset = data['train'].select(range(ds_len)).map(lambda x: {\"input_text\": \"Generate \" + x['section'] + \" for a \" + x['doctype'] + \" on topic \" + x['topic'] + \"\\n\" + x['content']})\n",
        "\n",
        "print(train_dataset[0])\n",
        "# Tokenize the datasets\n",
        "train_encodings = tokenizer(train_dataset['input_text'], max_length=256, truncation=True, padding=True, return_tensors='pt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  class TextDataset(Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item[\"labels\"] = item[\"input_ids\"].clone()\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings[\"input_ids\"])\n"
      ],
      "metadata": {
        "id": "whNBQA9m0EPb"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the encodings to PyTorch datasets\n",
        "train_dataset = TextDataset(train_encodings)"
      ],
      "metadata": {
        "id": "hrNxx33K0H9p"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example Before Fine Tuning"
      ],
      "metadata": {
        "id": "RWGTyUHhSZx-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(when_id):\n",
        "  print(ds_len)\n",
        "  doc_type = \"White Paper\"\n",
        "  topic = \"Infosys Watch Tower\"\n",
        "  keywords = \"\"\n",
        "  content_to_use = \"\"\n",
        "  #content_to_use = \"INFOSYS WATCH TOWER is AN AI PLATFORM FOR COMPREHENSIVE AIRPORT SECURITY. Infosys Watch Tower is an advanced AI platform that provides comprehensive security solutions for airports. It offers real-time monitoring capabilities to address the specific challenges faced by airports, such as crowd management and ensuring a secure environment. By integrating various sensors, including cameras, drones, and LiDAR, the platform detects incidents and gathers valuable information to streamline airport operations.With its cutting-edge technologies and scalability, Infosys Watch Tower enables efficient tracking of cargo and mitigates security threats effectively. The platform utilizes drones for inspecting aircraft and employs Non-destructive Testing (NDT) techniques using sonar to identify material damage. It leverages 5G technology to facilitate the creation of low-code/no-code AI workflows for installed sensors, enabling seamless configuration and deployment across multiple edges.Infosys Watch Tower offers a unified view of inferences, reports, monitoring plans, and alerts, providing management with a 360-degree visibility into different incidents and events. It serves as a valuable tool for security personnel, operations managers, and other stakeholders by enhancing their decision-making capabilities and ensuring the overall security and maintenance of the airport.The platform encompasses various use cases crucial to the aviation industry. It includes fire and smoke detection, enabling prompt identification and alerting security personnel. Bird monitoring is another significant aspect, as bird strikes pose a high risk to aircraft safety. By capturing images of birds flying over airfields, Infosys Watch Tower can notify authorities and trigger measures to divert the birds' path, preventing potential collisions.Furthermore, the platform facilitates unattended cabin baggage detection, effectively tracking baggage and identifying any unattended or abandoned luggage. It also offers features for perimeter monitoring, construction monitoring, and vegetation monitoring, addressing key concerns related to security breaches, construction safety, and wildlife interference.Infosys Watch Tower ensures a higher level of security, safety, and operational efficiency for airports, making it an indispensable solution in the aviation industry.\"\n",
        "\n",
        "  doc_content=\"\"\n",
        "  doc_parts=[\"Abstract\",\"Conclusion\"]\n",
        "  max_words=[100,100]\n",
        "  #doc_parts=[\"Abstract\",\"Introduction\",\"Problem Statement\",\"Methodology\",\"Conclusion\"]\n",
        "\n",
        "  for doc_part in doc_parts:\n",
        "    prompt = \"\"\n",
        "\n",
        "    #prompt0 = f\"Generate {doc_part} section for a {doc_type}.\\n\"\n",
        "    prompt1 = \"\"\n",
        "    if content_to_use.strip() != \"\":\n",
        "      prompt1 = f\"Here is some information about {topic}: {content_to_use}\\n\"\n",
        "\n",
        "    prompt2 = \"\"\n",
        "    if keywords.strip() != \"\":\n",
        "      prompt2= f\"Include the following keywords in your response: {keywords}.\\n\"\n",
        "\n",
        "    #prompt3=f\">>TITLE<<{doc_type} on {topic}\\n\"\n",
        "    prompt4 = f\"Generate {doc_part} for a {doc_type} on topic {topic}\\n\"\n",
        "    #prompt5=f\"## {doc_part}\\n\"\n",
        "\n",
        "    #prompt3 = f\"\\n>>QUESTION<<{questn}\\n>>ANSWER<<\"\n",
        "    #data['train']\n",
        "\n",
        "    prompt_parts = [prompt1, prompt2, prompt4]\n",
        "\n",
        "    for prompt_part in prompt_parts:\n",
        "      if prompt_part.strip() != \"\":\n",
        "        prompt += prompt_part\n",
        "\n",
        "    print(f\"\\n-------------\\nPrompt:\\n{prompt}\\n-------------\\n\")\n",
        "    encoding = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda:0\")\n",
        "\n",
        "    output = model.generate(\n",
        "        input_ids=encoding.input_ids,\n",
        "        attention_mask=encoding.attention_mask,\n",
        "        max_new_tokens=200,\n",
        "        max_time=600,\n",
        "        do_sample=True,\n",
        "        temperature=0.1,\n",
        "        repetition_penalty=10.0,\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "        top_k = 0\n",
        "    )\n",
        "\n",
        "    temp_content=tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "    #prompt_parts = [prompt0, prompt1, prompt2, prompt3.replace(\">>TITLE<<\",\"\"), prompt4]\n",
        "    for prompt_part in prompt_parts:\n",
        "      if prompt_part.strip() != \"\":\n",
        "        temp_content=temp_content.replace(prompt_part, \"\")\n",
        "\n",
        "    temp_content=f\"\\n## {doc_part}\\n\\n{temp_content}\\n\\n\"\n",
        "    print(temp_content)\n",
        "    doc_content+=temp_content\n",
        "\n",
        "  #print(doc_content)\n",
        "\n",
        "  f = open(topic.replace(\" \", \"-\")+\"-\"+when_id+\".md\", \"w\")\n",
        "  f.write(doc_content)\n",
        "  f.close()"
      ],
      "metadata": {
        "id": "xx4mKCzFPEM7"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#generate(\"before\")"
      ],
      "metadata": {
        "id": "2pRFK3thQ1XV"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "J53zPp1qSdZp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "iDniJ-bq4nxD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f9fbc890-91b5-425d-98ee-4631a65a1a9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-bd500a371ea7>:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [30/30 08:32, Epoch 30/30]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.033500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.055100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.059500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.031400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.044300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.028500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.009200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.951000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.961400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.893500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.864100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.863700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.879100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.802200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.835400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.781600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.722700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.706200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.681900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.669500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.665600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.691800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.628000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.672400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.666200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.606300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.622600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.588300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.588000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.584100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=30, training_loss=0.8062353014945984, metrics={'train_runtime': 529.3922, 'train_samples_per_second': 1.303, 'train_steps_per_second': 0.057, 'total_flos': 3516543150981120.0, 'train_loss': 0.8062353014945984, 'epoch': 30.0})"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "trainer = transformers.Trainer(\n",
        "    model=model,\n",
        "    train_dataset=train_dataset,\n",
        "    # eval_dataset=val_dataset,\n",
        "    args=transformers.TrainingArguments(\n",
        "        num_train_epochs=30,\n",
        "        per_device_train_batch_size=16,\n",
        "        gradient_accumulation_steps=4,\n",
        "        warmup_ratio=0.05,\n",
        "        # max_steps=100,\n",
        "        learning_rate=2e-4,\n",
        "        fp16=True,\n",
        "        logging_steps=1,\n",
        "        output_dir=\"outputs\",\n",
        "        optim=\"paged_adamw_8bit\",\n",
        "        lr_scheduler_type='cosine',\n",
        "    ),\n",
        "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
        ")\n",
        "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n",
        "\n",
        "#import gc\n",
        "#del train_encodings, data\n",
        "#gc.collect()\n",
        "#torch.cuda.empty_cache()\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example After Fine Tuning"
      ],
      "metadata": {
        "id": "KWXT-FNfSlpk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.config.use_cache = True\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "_9vrd1FXSz8W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2bef189-294f-4026-906e-370111618d4e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PeftModelForCausalLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): RWForCausalLM(\n",
              "      (transformer): RWModel(\n",
              "        (word_embeddings): Embedding(65024, 4544)\n",
              "        (h): ModuleList(\n",
              "          (0-31): 32 x DecoderLayer(\n",
              "            (input_layernorm): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n",
              "            (self_attention): Attention(\n",
              "              (maybe_rotary): RotaryEmbedding()\n",
              "              (query_key_value): Linear4bit(\n",
              "                in_features=4544, out_features=4672, bias=False\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4544, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=4672, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
              "              (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (mlp): MLP(\n",
              "              (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
              "              (act): GELU(approximate='none')\n",
              "              (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (ln_f): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (lm_head): Linear(in_features=4544, out_features=65024, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate(\"after\")"
      ],
      "metadata": {
        "id": "MezO1msTSnEs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "781106c4-2457-431f-b70d-22948e0b1d98"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23\n",
            "\n",
            "-------------\n",
            "Prompt:\n",
            "Generate Abstract for a White Paper on topic Infosys Watch Tower\n",
            "\n",
            "-------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "## Abstract\n",
            "\n",
            "The white paper “Infosys Watch Tower” is an analysis of the current state of security in enterprise networks and how to address these challenges. The report provides insights into key trends, drivers, barriers, opportunities, threats, use cases and recommendations. It also includes case studies from leading organizations that have implemented solutions based on this research. This document will help you understand the impact of cyberattacks on business operations and identify effective strategies to mitigate risks associated with them. By reading through it, you can gain valuable insight into various aspects related to cybersecurity such as threat landscape, vulnerabilities, mitigation measures and best practices. In addition, we provide actionable advice on implementing appropriate controls within your organization’s network architecture. We hope that our findings would be useful for decision makers who are looking forward to adopting new technologies or enhancing existing ones to improve their overall performance levels.\n",
            "\n",
            "\n",
            "\n",
            "-------------\n",
            "Prompt:\n",
            "Generate Conclusion for a White Paper on topic Infosys Watch Tower\n",
            "\n",
            "-------------\n",
            "\n",
            "\n",
            "## Conclusion\n",
            "\n",
            "In conclusion, the adoption of the Watch Tower solution by Infosys has enabled it to enhance its security posture and mitigate risks. The implementation of this technology has helped Infosys in achieving compliance with industry standards such as ISO 27001/2K3A and PCI DSS v3.1. It has also improved threat detection capabilities and reduced mean time to detect threats. However, there are some limitations associated with this solution that need to be addressed before deploying it at scale. These include lack of integration between different components, inability to identify anomalous behavior patterns, etc. Therefore, further research is required to address these challenges so that organizations can effectively leverage their data assets for business growth and innovation.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Abstract\n",
        "\n",
        "The white paper “Infosys Watch Tower” is an analysis of the current state of security in enterprise networks and how to address these challenges. The report provides insights into key trends, drivers, barriers, opportunities, threats, use cases and recommendations. It also includes case studies from leading organizations that have implemented solutions based on this research. This document will help you understand the impact of cyberattacks on business operations and identify effective strategies to mitigate risks associated with them. By reading through it, you can gain valuable insight into various aspects related to cybersecurity such as threat landscape, vulnerabilities, mitigation measures and best practices. In addition, we provide actionable advice on implementing appropriate controls within your organization’s network architecture. We hope that our findings would be useful for decision makers who are looking forward to adopting new technologies or enhancing existing ones to improve their overall performance levels.\n"
      ],
      "metadata": {
        "id": "U9TZfgQeQd19"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Abstract  \n",
        "\n",
        "\n",
        "The aviation industry is one of the most critical sectors in the global economy. With the rise of air travel, the industry is facing a number of challenges, including security threats, delays, and disruptions. To address these challenges, airports are introducing advanced technologies, such as AI, to improve the efficiency of their operations. Infosys Watch Tower is an AI platform that provides comprehensive security solutions for airports. It offers real-time monitoring capabilities to address the specific challenges faced by airports, such as crowd management and ensuring a secure environment. By integrating various sensors, including cameras, drones, and LiDAR, the platform detects incidents and gathers valuable information to streamline airport operations. With its cutting-edge technologies and scalability, Infosys Watch Tower enables efficient tracking of cargo and mitigates security threats effectively. The platform utilizes drones for inspecting aircraft and employs Non-destructive Testing (NDT) techniques using sonar to identify material damage. It leverages 5G technology to facilitate the creation of low-code  \n",
        "\n",
        "## Introduction  \n",
        "\n",
        "\n",
        "Infosys Watch Tower is an AI platform for comprehensive airport security solutions. It provides real-time monitoring capabilities to address the specific challenges faced by airports, such as crowd management and ensuring a secure environment. It is a cutting-edge technology platform that integrates various sensors, including cameras, drones, and LiDAR, to detect incidents and gather valuable information to streamline airport operations.Infosys Watch Tower is an AI platform that provides comprehensive security solutions for airports. It offers real-time monitoring capabilities to address the specific challenges faced by airports, such as crowd management and ensuring a secure environment. It is a cutting-edge technology platform that integrates various sensors, including cameras, drones, and LiDAR, to detect incidents and gather valuable information to streamline airport operations.\n",
        "Infosys Watch Tower is an AI platform for comprehensive airport security solutions. It provides real-time monitoring capabilities to address the specific challenges faced by airports, such as crowd management and ensuring a secure environment. It is a cutting  \n",
        "\n",
        "## Main Content  \n",
        "\n",
        "\n",
        "Infosys Watch Tower is an AI platform for comprehensive airport security. It offers real-time monitoring capabilities to address the specific challenges faced by airports, such as crowd management and ensuring a secure environment. By integrating various sensors, including cameras, drones, and LiDAR, the platform detects incidents and gathers valuable information to streamline airport operations.\n",
        "Infosys Watch Tower enables efficient tracking of cargo and mitigates security threats effectively. The platform utilizes drones for inspecting aircraft and employs Non-destructive Testing (NDT) techniques using sonar to identify material damage. It leverages 5G technology to facilitate the creation of low-code/no-code AI workflows for installed sensors, enabling seamless configuration and deployment across multiple edges.\n",
        "Infosys Watch Tower offers a unified view of inferences, reports, monitoring plans, and alerts, providing management with a 360-degree visibility into different incidents and events. It serves as a valuable tool for security personnel, operations managers, and other stakeholders  \n"
      ],
      "metadata": {
        "id": "wbhTR_xWDQPv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save the Model"
      ],
      "metadata": {
        "id": "w60z4hyJzdaW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if (save_trained_model):\n",
        "  model.save_pretrained(\"model-falcon-trained\")\n",
        "  !huggingface-cli login --token $HF_TOKEN\n",
        "  model.push_to_hub(\"rai-sandeep/model-falcon-trained\")"
      ],
      "metadata": {
        "id": "SDRHSSnZznmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8bK8VfO33_WI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prompt_and_generate():\n",
        "\n",
        "  doc_type = input(\"What type of document do you want to generate? (Enter White Paper or Press Release)\\n\")\n",
        "  topic = input(f\"On what topic do you want to generate the {doc_type}?\\n\")\n",
        "  keywords = input(f\"Enter any keywords that should be part of the {doc_type} in comma separated format. If none, press Enter.\\n\")\n",
        "  content_to_use = input(f\"Enter any content that should be used for the {doc_type}. If none, press Enter.\\n\")\n",
        "\n",
        "  doc_content=\"\"\n",
        "  doc_parts=[\"Abstract\",\"Introduction\",\"Problem Statement\",\"Methodology\",\"Findings and Analysis\",\"Recommendations\",\"Conclusion\"]\n",
        "\n",
        "  for doc_part in doc_parts:\n",
        "    prompt = f\"Generate a {doc_type} {doc_part} on {topic}.\"\n",
        "    if keywords.strip() != \"\":\n",
        "      prompt += f\"\\nInclude the following keywords: {keywords}.\"\n",
        "    if content_to_use.strip() != \"\":\n",
        "      prompt += f\"\\nHere is some context about {topic}: {content_to_use}.\\n\"\n",
        "\n",
        "    encoding = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda:0\")\n",
        "    output = model.generate(input_ids=encoding.input_ids, attention_mask=encoding.attention_mask, max_new_tokens=max_tok, do_sample=True, temperature=tempre, eos_token_id=tokenizer.eos_token_id, top_k = 0)\n",
        "\n",
        "    temp_content=tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    temp_content=temp_content.replace(prompt, \"\")\n",
        "    doc_content+=f\"\\n## {doc_part}  \\n{temp_content}  \\n\"\n",
        "\n",
        "  print(doc_content)\n",
        "\n",
        "  f = open(topic.replace(\" \", \"-\")+\".md\", \"w\")\n",
        "  f.write(doc_content)\n",
        "  f.close()"
      ],
      "metadata": {
        "id": "rFjXfYivrnGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prompt_and_generate()"
      ],
      "metadata": {
        "id": "79gmk3y1v6WK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d5165c975b6d4f858adf6a942d8ce603": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_247b9fb9b9ef41c081a789bfdfc91d6d",
              "IPY_MODEL_d4e9bf6bbb9547d7ad3c8f90681889d4",
              "IPY_MODEL_f029ba63c1f84cea95ae0e67b3308896"
            ],
            "layout": "IPY_MODEL_2cc11e3e6de14442a55b6a2bc6b528b7"
          }
        },
        "247b9fb9b9ef41c081a789bfdfc91d6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e33cb654fc984f62b9a399c43375c60a",
            "placeholder": "​",
            "style": "IPY_MODEL_e124c9e1b256441bbde82eeea4b73b6b",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "d4e9bf6bbb9547d7ad3c8f90681889d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e7fd6e4ac37406c8fa29b5d664d1b5b",
            "max": 15,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_91b38304376141ac8b4b8d5229022b5c",
            "value": 15
          }
        },
        "f029ba63c1f84cea95ae0e67b3308896": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e2a13025a2b471a9403f76a1ad6f2cb",
            "placeholder": "​",
            "style": "IPY_MODEL_d0fc4d839e3540338e7b4e06913b7dd5",
            "value": " 15/15 [02:32&lt;00:00,  8.35s/it]"
          }
        },
        "2cc11e3e6de14442a55b6a2bc6b528b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e33cb654fc984f62b9a399c43375c60a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e124c9e1b256441bbde82eeea4b73b6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e7fd6e4ac37406c8fa29b5d664d1b5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91b38304376141ac8b4b8d5229022b5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4e2a13025a2b471a9403f76a1ad6f2cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0fc4d839e3540338e7b4e06913b7dd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b0b1208a39ad467da6b76dcd0b1fcfbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e7a6a99c066248249d0004d33e73f4fa",
              "IPY_MODEL_b13770c8758c415a9f6d719065378101",
              "IPY_MODEL_c50f26e480334f26841cf0bd97ad63c5"
            ],
            "layout": "IPY_MODEL_8ec60d4e340e43c39880e6c8dd5ae08e"
          }
        },
        "e7a6a99c066248249d0004d33e73f4fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cae3b9d0945e4de3a1a9668ab7b95fff",
            "placeholder": "​",
            "style": "IPY_MODEL_944ffb5ee6a744f0840026954a0548c5",
            "value": "100%"
          }
        },
        "b13770c8758c415a9f6d719065378101": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_351e130072564c0d87568671bdfb84bd",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_26a5c7d1081b4da9980b8fab9d9d67f8",
            "value": 1
          }
        },
        "c50f26e480334f26841cf0bd97ad63c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71f322d3d5f547d0b004a9cb71a170b5",
            "placeholder": "​",
            "style": "IPY_MODEL_2572bff465524b4c807b51b649a832a6",
            "value": " 1/1 [00:00&lt;00:00, 42.60it/s]"
          }
        },
        "8ec60d4e340e43c39880e6c8dd5ae08e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cae3b9d0945e4de3a1a9668ab7b95fff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "944ffb5ee6a744f0840026954a0548c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "351e130072564c0d87568671bdfb84bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26a5c7d1081b4da9980b8fab9d9d67f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "71f322d3d5f547d0b004a9cb71a170b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2572bff465524b4c807b51b649a832a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a2e00f23d0c429a8721e50f4264a1f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eb2cd01478ea49c58421d6f0b43e34d6",
              "IPY_MODEL_2c325a83f05f49d3b7985b127ac1c288",
              "IPY_MODEL_a020dadab920451e81ec7fda70fa4f06"
            ],
            "layout": "IPY_MODEL_34e515b47e73438e9ef8c68390741a16"
          }
        },
        "eb2cd01478ea49c58421d6f0b43e34d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19fbd49126e4460ea9b2f581e1e9ad38",
            "placeholder": "​",
            "style": "IPY_MODEL_7ff5d3f72e8041d49bd9c493e415453f",
            "value": "Map:   0%"
          }
        },
        "2c325a83f05f49d3b7985b127ac1c288": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20eb1cd1d16e4376b5aa4ebe3d25b8bb",
            "max": 23,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b9b3e41cfd8146edb750d5843b9c1f0a",
            "value": 23
          }
        },
        "a020dadab920451e81ec7fda70fa4f06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1fe68941b14a4e18b4154fdaaee09e19",
            "placeholder": "​",
            "style": "IPY_MODEL_c24dd9d0428642189829752ce5992439",
            "value": " 0/23 [00:00&lt;?, ? examples/s]"
          }
        },
        "34e515b47e73438e9ef8c68390741a16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "19fbd49126e4460ea9b2f581e1e9ad38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ff5d3f72e8041d49bd9c493e415453f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20eb1cd1d16e4376b5aa4ebe3d25b8bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9b3e41cfd8146edb750d5843b9c1f0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1fe68941b14a4e18b4154fdaaee09e19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c24dd9d0428642189829752ce5992439": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}