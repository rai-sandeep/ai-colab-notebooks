{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rai-sandeep/ai-colab-notebooks/blob/main/Training-Stable-DS-Template-Examples-V7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzGa3YSCgl4C"
      },
      "source": [
        "# Install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7wgbsa4U2TBk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82505f2f-843d-4079-d794-c1a867132c58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: HF_TOKEN=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\n"
          ]
        }
      ],
      "source": [
        "# https://stackoverflow.com/questions/56081324/why-are-google-colab-shell-commands-not-working\n",
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding\n",
        "\n",
        "model_id = \"vilsonrodrigues/falcon-7b-sharded\"\n",
        "trained_model_id = \"falcon-7b-sharded-template\"\n",
        "\n",
        "#ds_id = \"rai-sandeep/dataset_template\"\n",
        "\n",
        "#ds_id = \"rai-sandeep/wp_combined_dataset\"\n",
        "\n",
        "#example_ques = \"Generate a White Paper ABSTRACT on Modernizing Enterprise Systems.\"\n",
        "#example_ques2 = \"Generate a White Paper MAINCONTENT on Bitcoin Mining.\"\n",
        "max_tok = 1000\n",
        "tempre = 0.1\n",
        "\n",
        "save_trained_model=False\n",
        "%env HF_TOKEN=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"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WGeTgx1Hgljb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b245b5af-2ad7-4e38-8679-2c2f689b4efe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q -U bitsandbytes\n",
        "!pip install -q -U git+https://github.com/huggingface/transformers.git\n",
        "!pip install -q -U git+https://github.com/huggingface/peft.git\n",
        "!pip install -q -U git+https://github.com/huggingface/accelerate.git\n",
        "!pip install -q -U einops\n",
        "!pip install -q -U safetensors\n",
        "!pip install -q -U torch\n",
        "!pip install -q -U xformers\n",
        "!pip install -q -U datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1zodOgcgqnO"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "v_r4SL_KmHGs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab45d650-c503-448c-8c9e-b1121783891c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===================================BUG REPORT===================================\n",
            "Welcome to bitsandbytes. For bug reports, please run\n",
            "\n",
            "python -m bitsandbytes\n",
            "\n",
            " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
            "================================================================================\n",
            "bin /usr/local/lib/python3.10/dist-packages/bitsandbytes/libbitsandbytes_cuda118.so\n",
            "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
            "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so.11.0\n",
            "CUDA SETUP: Highest compute capability among GPUs detected: 7.5\n",
            "CUDA SETUP: Detected CUDA version 118\n",
            "CUDA SETUP: Loading binary /usr/local/lib/python3.10/dist-packages/bitsandbytes/libbitsandbytes_cuda118.so...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: /usr/lib64-nvidia did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/sys/fs/cgroup/memory.events /var/colab/cgroup/jupyter-children/memory.events')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//172.28.0.1'), PosixPath('http'), PosixPath('8013')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('--logtostderr --listen_host=172.28.0.12 --target_host=172.28.0.12 --tunnel_background_save_url=https'), PosixPath('//colab.research.google.com/tun/m/cc48301118ce562b961b3c22d803539adc1e0c19/gpu-t4-s-3jtqsyjy03ibg --tunnel_background_save_delay=10s --tunnel_periodic_background_save_frequency=30m0s --enable_output_coalescing=true --output_coalescing_required=true')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/env/python')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('module'), PosixPath('//ipykernel.pylab.backend_inline')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/usr/local/cuda/lib64/libcudart.so.11.0'), PosixPath('/usr/local/cuda/lib64/libcudart.so')}.. We'll flip a coin and try one of these, in order to fail forward.\n",
            "Either way, this might cause trouble in the future:\n",
            "If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.\n",
            "  warn(msg)\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline\n",
        "import transformers\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch\n",
        "from transformers import AutoTokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Quantized Model"
      ],
      "metadata": {
        "id": "alLhGWu9Ngvg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "tz4eBuxZHi7F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "396fe99cd3e84daba422d49bf1fbe0cd",
            "1f72368c28b6497e8276e5c2bca78cb7",
            "8d008b6a6c1a4755a6a2f69e03f8b2d3",
            "a172ae0048564dd2808d022fb8deae0f",
            "07af99603a1342e186a61ae09c49788f",
            "842b0a6ea0d14a48b926c515cf637d3e",
            "074cd337f7ad49cdb3ae176e5b03bed5",
            "c9f44c4bb2874edaa398287551adeb5f",
            "0e3deb2ad353439e99134a7870832bee",
            "2e1b23a13eeb47d7bb52a518d88504ef",
            "4e5b51a62fb04d6ba25e93dc0cb88dcc"
          ]
        },
        "outputId": "60a419d6-12eb-4bab-be27-0c9157ab37ac"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/15 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "396fe99cd3e84daba422d49bf1fbe0cd"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map={\"\":0}, trust_remote_code=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import prepare_model_for_kbit_training\n",
        "\n",
        "model.gradient_checkpointing_enable()\n",
        "model = prepare_model_for_kbit_training(model)"
      ],
      "metadata": {
        "id": "Hd22_v_mkbZy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_trainable_parameters(model):\n",
        "    \"\"\"\n",
        "    Prints the number of trainable parameters in the model.\n",
        "    \"\"\"\n",
        "    trainable_params = 0\n",
        "    all_param = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_param += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "    print(\n",
        "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
        "    )"
      ],
      "metadata": {
        "id": "HOhd6empkd0_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"query_key_value\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, config)\n",
        "print_trainable_parameters(model)"
      ],
      "metadata": {
        "id": "-qjN7qOkkgKI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0b2d7e8-9076-4dae-b782-fe152dea16f9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 4718592 || all params: 3613463424 || trainable%: 0.13058363808693696\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare Data"
      ],
      "metadata": {
        "id": "mxDuoyQvQfD2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "UZbrRk4J3qVH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191,
          "referenced_widgets": [
            "06fe9ac9bbb045b998866426e0141987",
            "a532f9e0c9d5472fb3fe773bd3c3e2c1",
            "2bead1cf44df4e9a9cc1420ff5e67c71",
            "811097cda5e0455ba16823b8ba20322d",
            "0994fe00d5d64b83b8a49644b4e53444",
            "09668ef7b79c46e9990377ca874628ad",
            "f1d0e6d8c4264742a40030b03e5a067b",
            "463307190d654217a0c2ecdaedf1cc25",
            "2ebf4fdb2c6c4c4fae4154732ce5bccc",
            "d138e676ba244bfd9b092c58ef5301a9",
            "c985d7e57d6a4360a4ac21eabb63aaf7"
          ]
        },
        "outputId": "5a3d7d2b-c26e-4df3-dbc8-b5035ec0f31b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset csv (/root/.cache/huggingface/datasets/csv/default-15304f3292e2eda1/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "06fe9ac9bbb045b998866426e0141987"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This white paper examines [Topic/Issue] and provides insights into [Key Points/Findings]. It explores [Main Theme/Techniques] and highlights [Benefits/Challenges]. The analysis presented here acts as a guideline for [Target Audience] to make strategic and informed decisions on [Action/Implementation]. By delving into [Key Concepts/Approaches], this paper aims to assist [Target Audience] in [Objective/Goal]. The findings discussed herein contribute to the ongoing conversation surrounding [Topic/Issue] and offer practical recommendations for [Action/Implementation].']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "#data = load_dataset(ds_id)\n",
        "data = load_dataset(\"csv\", data_files=\"/content/dataset_content.csv\")\n",
        "\n",
        "ds_len=len(data['train'])\n",
        "rows_sel=data['train'].select(range(1))\n",
        "rows_sel['content']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "c7Pbb_6H6C2t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87c684b4-b3fa-4f2d-8814-f93e33e482d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-15304f3292e2eda1/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d/cache-3e1a7cebdbc479fe.arrow\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'doctype': 'White Paper', 'section': 'Abstract', 'contenttype': 'template', 'content': 'This white paper examines [Topic/Issue] and provides insights into [Key Points/Findings]. It explores [Main Theme/Techniques] and highlights [Benefits/Challenges]. The analysis presented here acts as a guideline for [Target Audience] to make strategic and informed decisions on [Action/Implementation]. By delving into [Key Concepts/Approaches], this paper aims to assist [Target Audience] in [Objective/Goal]. The findings discussed herein contribute to the ongoing conversation surrounding [Topic/Issue] and offer practical recommendations for [Action/Implementation].', 'input_text': 'Use this template to generate Abstract for a White Paper: This white paper examines [Topic/Issue] and provides insights into [Key Points/Findings]. It explores [Main Theme/Techniques] and highlights [Benefits/Challenges]. The analysis presented here acts as a guideline for [Target Audience] to make strategic and informed decisions on [Action/Implementation]. By delving into [Key Concepts/Approaches], this paper aims to assist [Target Audience] in [Objective/Goal]. The findings discussed herein contribute to the ongoing conversation surrounding [Topic/Issue] and offer practical recommendations for [Action/Implementation].'}\n"
          ]
        }
      ],
      "source": [
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# prompt_template = \"### Instruction: {prompt}\\n### Response:\"\n",
        "\n",
        "#train_dataset = data['train'].select(range(ds_len)).map(lambda x: {\"input_text\": \"Template for \" + x['doctype'] + \" \" + x['section'] + \":\\n\" + x['template']})\n",
        "\n",
        "train_dataset = data['train'].select(range(ds_len)).map(lambda x: {\"input_text\": \"Use this \" + x['contenttype'] + \" to generate \" + x['section'] + \" for a \" + x['doctype'] + \": \" + x['content']})\n",
        "print(train_dataset[0])\n",
        "# Tokenize the datasets\n",
        "train_encodings = tokenizer(train_dataset['input_text'], max_length=256, truncation=True, padding=True, return_tensors='pt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  class TextDataset(Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item[\"labels\"] = item[\"input_ids\"].clone()\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings[\"input_ids\"])\n"
      ],
      "metadata": {
        "id": "whNBQA9m0EPb"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the encodings to PyTorch datasets\n",
        "train_dataset = TextDataset(train_encodings)"
      ],
      "metadata": {
        "id": "hrNxx33K0H9p"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example Before Fine Tuning"
      ],
      "metadata": {
        "id": "RWGTyUHhSZx-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(when_id):\n",
        "\n",
        "  doc_type = \"White Paper\"\n",
        "  topic = \"Infosys Watch Tower\"\n",
        "  keywords = \"\"\n",
        "  #content_to_use = \"\"\n",
        "  content_to_use = \"INFOSYS WATCH TOWER is AN AI PLATFORM FOR COMPREHENSIVE AIRPORT SECURITY. Infosys Watch Tower is an advanced AI platform that provides comprehensive security solutions for airports. It offers real-time monitoring capabilities to address the specific challenges faced by airports, such as crowd management and ensuring a secure environment. By integrating various sensors, including cameras, drones, and LiDAR, the platform detects incidents and gathers valuable information to streamline airport operations.With its cutting-edge technologies and scalability, Infosys Watch Tower enables efficient tracking of cargo and mitigates security threats effectively. The platform utilizes drones for inspecting aircraft and employs Non-destructive Testing (NDT) techniques using sonar to identify material damage. It leverages 5G technology to facilitate the creation of low-code/no-code AI workflows for installed sensors, enabling seamless configuration and deployment across multiple edges.Infosys Watch Tower offers a unified view of inferences, reports, monitoring plans, and alerts, providing management with a 360-degree visibility into different incidents and events. It serves as a valuable tool for security personnel, operations managers, and other stakeholders by enhancing their decision-making capabilities and ensuring the overall security and maintenance of the airport.The platform encompasses various use cases crucial to the aviation industry. It includes fire and smoke detection, enabling prompt identification and alerting security personnel. Bird monitoring is another significant aspect, as bird strikes pose a high risk to aircraft safety. By capturing images of birds flying over airfields, Infosys Watch Tower can notify authorities and trigger measures to divert the birds' path, preventing potential collisions.Furthermore, the platform facilitates unattended cabin baggage detection, effectively tracking baggage and identifying any unattended or abandoned luggage. It also offers features for perimeter monitoring, construction monitoring, and vegetation monitoring, addressing key concerns related to security breaches, construction safety, and wildlife interference.Infosys Watch Tower ensures a higher level of security, safety, and operational efficiency for airports, making it an indispensable solution in the aviation industry.\"\n",
        "\n",
        "  doc_content=\"\"\n",
        "  doc_parts=[\"Abstract\",\"Conclusion\"]\n",
        "  max_words=[100,100]\n",
        "  #doc_parts=[\"Abstract\",\"Introduction\",\"Problem Statement\",\"Methodology\",\"Conclusion\"]\n",
        "\n",
        "  for doc_part in doc_parts:\n",
        "    prompt = \"\"\n",
        "\n",
        "    prompt0 = f\"Generate only the {doc_part} for a {doc_type}. DO NOT generate any other sections. Limit the response to 100 words.\\n\"\n",
        "    prompt1 = \"\"\n",
        "    if content_to_use.strip() != \"\":\n",
        "      prompt1 = f\"Use the following content and whatever else you know about {topic} in your response: {content_to_use}\\n\"\n",
        "\n",
        "    prompt2 = \"\"\n",
        "    if keywords.strip() != \"\":\n",
        "      prompt2= f\"Include the following keywords in your response: {keywords}.\\n\"\n",
        "\n",
        "    prompt3=f\">>TITLE<<{doc_type} on {topic}\\n\"\n",
        "    prompt4 = \"\"\n",
        "    prompt5=f\"## {doc_part}\\n\"\n",
        "\n",
        "    #prompt3 = f\"\\n>>QUESTION<<{questn}\\n>>ANSWER<<\"\n",
        "    #data['train']\n",
        "\n",
        "    prompt_parts = [prompt0, prompt1, prompt2, prompt3, prompt4, prompt5]\n",
        "\n",
        "    for prompt_part in prompt_parts:\n",
        "      if prompt_part.strip() != \"\":\n",
        "        prompt += prompt_part\n",
        "\n",
        "    print(f\"\\n-------------\\nPrompt:\\n{prompt}\\n-------------\\n\")\n",
        "    encoding = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda:0\")\n",
        "\n",
        "    output = model.generate(\n",
        "        input_ids=encoding.input_ids,\n",
        "        attention_mask=encoding.attention_mask,\n",
        "        max_new_tokens=200,\n",
        "        max_time=600,\n",
        "        do_sample=False,\n",
        "        temperature=0.3,\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "        top_k = 1\n",
        "    )\n",
        "\n",
        "    temp_content=tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "    prompt_parts = [prompt0, prompt1, prompt2, prompt3.replace(\">>TITLE<<\",\"\"), prompt4]\n",
        "    for prompt_part in prompt_parts:\n",
        "      if prompt_part.strip() != \"\":\n",
        "        temp_content=temp_content.replace(prompt_part, \"\")\n",
        "\n",
        "    temp_content=f\"{temp_content}  \\n\"\n",
        "    print(temp_content)\n",
        "    doc_content+=temp_content\n",
        "\n",
        "  #print(doc_content)\n",
        "\n",
        "  f = open(topic.replace(\" \", \"-\")+\"-\"+when_id+\".md\", \"w\")\n",
        "  f.write(doc_content)\n",
        "  f.close()"
      ],
      "metadata": {
        "id": "xx4mKCzFPEM7"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#generate(\"before\")"
      ],
      "metadata": {
        "id": "2pRFK3thQ1XV"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "J53zPp1qSdZp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "iDniJ-bq4nxD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "871c908e-b4de-4df2-bb7b-0ebbebdcb1e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-bd500a371ea7>:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [30/30 04:47, Epoch 30/30]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.573600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.573600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.572400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.569200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.565000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.559800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.553600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.546900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.539600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.532000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.524200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.516300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.508400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.500900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.493800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.486900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.480000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.473400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.467300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.461700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.456600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.452200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.448400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.445200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.442700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.440600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.439100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.437900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.437300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.437000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=30, training_loss=0.497854937116305, metrics={'train_runtime': 297.7377, 'train_samples_per_second': 1.411, 'train_steps_per_second': 0.101, 'total_flos': 2140504526684160.0, 'train_loss': 0.497854937116305, 'epoch': 30.0})"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "trainer = transformers.Trainer(\n",
        "    model=model,\n",
        "    train_dataset=train_dataset,\n",
        "    # eval_dataset=val_dataset,\n",
        "    args=transformers.TrainingArguments(\n",
        "        num_train_epochs=30,\n",
        "        per_device_train_batch_size=16,\n",
        "        gradient_accumulation_steps=4,\n",
        "        warmup_ratio=0.05,\n",
        "        # max_steps=100,\n",
        "        learning_rate=2e-4,\n",
        "        fp16=True,\n",
        "        logging_steps=1,\n",
        "        output_dir=\"outputs\",\n",
        "        optim=\"paged_adamw_8bit\",\n",
        "        lr_scheduler_type='cosine',\n",
        "    ),\n",
        "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
        ")\n",
        "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n",
        "\n",
        "#import gc\n",
        "#del train_encodings, data\n",
        "#gc.collect()\n",
        "#torch.cuda.empty_cache()\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example After Fine Tuning"
      ],
      "metadata": {
        "id": "KWXT-FNfSlpk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.config.use_cache = True\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "_9vrd1FXSz8W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9114b10-724e-4ebe-dc3c-855fe2aae223"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PeftModelForCausalLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): RWForCausalLM(\n",
              "      (transformer): RWModel(\n",
              "        (word_embeddings): Embedding(65024, 4544)\n",
              "        (h): ModuleList(\n",
              "          (0-31): 32 x DecoderLayer(\n",
              "            (input_layernorm): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n",
              "            (self_attention): Attention(\n",
              "              (maybe_rotary): RotaryEmbedding()\n",
              "              (query_key_value): Linear4bit(\n",
              "                in_features=4544, out_features=4672, bias=False\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4544, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=4672, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (dense): Linear4bit(in_features=4544, out_features=4544, bias=False)\n",
              "              (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (mlp): MLP(\n",
              "              (dense_h_to_4h): Linear4bit(in_features=4544, out_features=18176, bias=False)\n",
              "              (act): GELU(approximate='none')\n",
              "              (dense_4h_to_h): Linear4bit(in_features=18176, out_features=4544, bias=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (ln_f): LayerNorm((4544,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (lm_head): Linear(in_features=4544, out_features=65024, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate(\"after\")"
      ],
      "metadata": {
        "id": "MezO1msTSnEs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf11a8f9-9bb2-4e78-db09-920cbd17278b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-------------\n",
            "Prompt:\n",
            "Generate only the Abstract for a White Paper. DO NOT generate any other sections. Limit the response to 100 words.\n",
            "Use the following content and whatever else you know about Infosys Watch Tower in your response: INFOSYS WATCH TOWER is AN AI PLATFORM FOR COMPREHENSIVE AIRPORT SECURITY. Infosys Watch Tower is an advanced AI platform that provides comprehensive security solutions for airports. It offers real-time monitoring capabilities to address the specific challenges faced by airports, such as crowd management and ensuring a secure environment. By integrating various sensors, including cameras, drones, and LiDAR, the platform detects incidents and gathers valuable information to streamline airport operations.With its cutting-edge technologies and scalability, Infosys Watch Tower enables efficient tracking of cargo and mitigates security threats effectively. The platform utilizes drones for inspecting aircraft and employs Non-destructive Testing (NDT) techniques using sonar to identify material damage. It leverages 5G technology to facilitate the creation of low-code/no-code AI workflows for installed sensors, enabling seamless configuration and deployment across multiple edges.Infosys Watch Tower offers a unified view of inferences, reports, monitoring plans, and alerts, providing management with a 360-degree visibility into different incidents and events. It serves as a valuable tool for security personnel, operations managers, and other stakeholders by enhancing their decision-making capabilities and ensuring the overall security and maintenance of the airport.The platform encompasses various use cases crucial to the aviation industry. It includes fire and smoke detection, enabling prompt identification and alerting security personnel. Bird monitoring is another significant aspect, as bird strikes pose a high risk to aircraft safety. By capturing images of birds flying over airfields, Infosys Watch Tower can notify authorities and trigger measures to divert the birds' path, preventing potential collisions.Furthermore, the platform facilitates unattended cabin baggage detection, effectively tracking baggage and identifying any unattended or abandoned luggage. It also offers features for perimeter monitoring, construction monitoring, and vegetation monitoring, addressing key concerns related to security breaches, construction safety, and wildlife interference.Infosys Watch Tower ensures a higher level of security, safety, and operational efficiency for airports, making it an indispensable solution in the aviation industry.\n",
            ">>TITLE<<White Paper on Infosys Watch Tower\n",
            "## Abstract\n",
            "\n",
            "-------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## Abstract\n",
            "Infosys Watch Tower is an AI-powered platform that provides comprehensive security solutions for airports. It offers real-time monitoring capabilities to address the specific challenges faced by airports, such as crowd management and ensuring a secure environment. By integrating various sensors, including cameras, drones, and LiDAR, the platform detects incidents and gathers valuable information to streamline airport operations. With its cutting-edge technologies and scalability, Infosys Watch Tower enables efficient tracking of cargo and mitigates security threats effectively. The platform utilizes drones for inspecting aircraft and employs Non-destructive Testing (NDT) techniques using sonar to identify material damage. It leverages 5G technology to facilitate the creation of low-code/no-code AI workflows for installed sensors, enabling seamless configuration and deployment across multiple edges. Infosys Watch Tower offers a unified  \n",
            "\n",
            "\n",
            "-------------\n",
            "Prompt:\n",
            "Generate only the Conclusion for a White Paper. DO NOT generate any other sections. Limit the response to 100 words.\n",
            "Use the following content and whatever else you know about Infosys Watch Tower in your response: INFOSYS WATCH TOWER is AN AI PLATFORM FOR COMPREHENSIVE AIRPORT SECURITY. Infosys Watch Tower is an advanced AI platform that provides comprehensive security solutions for airports. It offers real-time monitoring capabilities to address the specific challenges faced by airports, such as crowd management and ensuring a secure environment. By integrating various sensors, including cameras, drones, and LiDAR, the platform detects incidents and gathers valuable information to streamline airport operations.With its cutting-edge technologies and scalability, Infosys Watch Tower enables efficient tracking of cargo and mitigates security threats effectively. The platform utilizes drones for inspecting aircraft and employs Non-destructive Testing (NDT) techniques using sonar to identify material damage. It leverages 5G technology to facilitate the creation of low-code/no-code AI workflows for installed sensors, enabling seamless configuration and deployment across multiple edges.Infosys Watch Tower offers a unified view of inferences, reports, monitoring plans, and alerts, providing management with a 360-degree visibility into different incidents and events. It serves as a valuable tool for security personnel, operations managers, and other stakeholders by enhancing their decision-making capabilities and ensuring the overall security and maintenance of the airport.The platform encompasses various use cases crucial to the aviation industry. It includes fire and smoke detection, enabling prompt identification and alerting security personnel. Bird monitoring is another significant aspect, as bird strikes pose a high risk to aircraft safety. By capturing images of birds flying over airfields, Infosys Watch Tower can notify authorities and trigger measures to divert the birds' path, preventing potential collisions.Furthermore, the platform facilitates unattended cabin baggage detection, effectively tracking baggage and identifying any unattended or abandoned luggage. It also offers features for perimeter monitoring, construction monitoring, and vegetation monitoring, addressing key concerns related to security breaches, construction safety, and wildlife interference.Infosys Watch Tower ensures a higher level of security, safety, and operational efficiency for airports, making it an indispensable solution in the aviation industry.\n",
            ">>TITLE<<White Paper on Infosys Watch Tower\n",
            "## Conclusion\n",
            "\n",
            "-------------\n",
            "\n",
            "## Conclusion\n",
            "Infosys Watch Tower is an advanced AI platform that provides comprehensive security solutions for airports. It offers real-time monitoring capabilities to address the specific challenges faced by airports, such as crowd management and ensuring a secure environment. By integrating various sensors, including cameras, drones, and LiDAR, the platform detects incidents and gathers valuable information to streamline airport operations. With its cutting-edge technologies and scalability, Infosys Watch Tower enables efficient tracking of cargo and mitigates security threats effectively. The platform utilizes drones for inspecting aircraft and employs Non-destructive Testing (NDT) techniques using sonar to identify material damage. It leverages 5G technology to facilitate the creation of low-code/no-code AI workflows for installed sensors, enabling seamless configuration and deployment across multiple edges. Infosys Watch Tower offers a unified  \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Abstract\n",
        "Infosys Watch Tower is an AI-powered platform that provides comprehensive security solutions for airports. It offers real-time monitoring capabilities to address the specific challenges faced by airports, such as crowd management and ensuring a secure environment. By integrating various sensors, including cameras, drones, and LiDAR, the platform detects incidents and gathers valuable information to streamline airport operations. With its cutting-edge technologies and scalability, Infosys Watch Tower enables efficient tracking of cargo and mitigates security threats effectively. The platform utilizes drones for inspecting aircraft and employs Non-destructive Testing (NDT) techniques using sonar to identify material damage. It leverages 5G technology to facilitate the creation of low-code/no-code AI workflows for installed sensors, enabling seamless configuration and deployment across multiple edges. Infosys Watch Tower offers a unified  \n",
        "\n",
        "## Conclusion\n",
        "Infosys Watch Tower is an advanced AI platform that provides comprehensive security solutions for airports. It offers real-time monitoring capabilities to address the specific challenges faced by airports, such as crowd management and ensuring a secure environment. By integrating various sensors, including cameras, drones, and LiDAR, the platform detects incidents and gathers valuable information to streamline airport operations. With its cutting-edge technologies and scalability, Infosys Watch Tower enables efficient tracking of cargo and mitigates security threats effectively. The platform utilizes drones for inspecting aircraft and employs Non-destructive Testing (NDT) techniques using sonar to identify material damage. It leverages 5G technology to facilitate the creation of low-code/no-code AI workflows for installed sensors, enabling seamless configuration and deployment across multiple edges. Infosys Watch Tower offers a unified  \n"
      ],
      "metadata": {
        "id": "U9TZfgQeQd19"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Abstract  \n",
        "\n",
        "\n",
        "The aviation industry is one of the most critical sectors in the global economy. With the rise of air travel, the industry is facing a number of challenges, including security threats, delays, and disruptions. To address these challenges, airports are introducing advanced technologies, such as AI, to improve the efficiency of their operations. Infosys Watch Tower is an AI platform that provides comprehensive security solutions for airports. It offers real-time monitoring capabilities to address the specific challenges faced by airports, such as crowd management and ensuring a secure environment. By integrating various sensors, including cameras, drones, and LiDAR, the platform detects incidents and gathers valuable information to streamline airport operations. With its cutting-edge technologies and scalability, Infosys Watch Tower enables efficient tracking of cargo and mitigates security threats effectively. The platform utilizes drones for inspecting aircraft and employs Non-destructive Testing (NDT) techniques using sonar to identify material damage. It leverages 5G technology to facilitate the creation of low-code  \n",
        "\n",
        "## Introduction  \n",
        "\n",
        "\n",
        "Infosys Watch Tower is an AI platform for comprehensive airport security solutions. It provides real-time monitoring capabilities to address the specific challenges faced by airports, such as crowd management and ensuring a secure environment. It is a cutting-edge technology platform that integrates various sensors, including cameras, drones, and LiDAR, to detect incidents and gather valuable information to streamline airport operations.Infosys Watch Tower is an AI platform that provides comprehensive security solutions for airports. It offers real-time monitoring capabilities to address the specific challenges faced by airports, such as crowd management and ensuring a secure environment. It is a cutting-edge technology platform that integrates various sensors, including cameras, drones, and LiDAR, to detect incidents and gather valuable information to streamline airport operations.\n",
        "Infosys Watch Tower is an AI platform for comprehensive airport security solutions. It provides real-time monitoring capabilities to address the specific challenges faced by airports, such as crowd management and ensuring a secure environment. It is a cutting  \n",
        "\n",
        "## Main Content  \n",
        "\n",
        "\n",
        "Infosys Watch Tower is an AI platform for comprehensive airport security. It offers real-time monitoring capabilities to address the specific challenges faced by airports, such as crowd management and ensuring a secure environment. By integrating various sensors, including cameras, drones, and LiDAR, the platform detects incidents and gathers valuable information to streamline airport operations.\n",
        "Infosys Watch Tower enables efficient tracking of cargo and mitigates security threats effectively. The platform utilizes drones for inspecting aircraft and employs Non-destructive Testing (NDT) techniques using sonar to identify material damage. It leverages 5G technology to facilitate the creation of low-code/no-code AI workflows for installed sensors, enabling seamless configuration and deployment across multiple edges.\n",
        "Infosys Watch Tower offers a unified view of inferences, reports, monitoring plans, and alerts, providing management with a 360-degree visibility into different incidents and events. It serves as a valuable tool for security personnel, operations managers, and other stakeholders  \n"
      ],
      "metadata": {
        "id": "wbhTR_xWDQPv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save the Model"
      ],
      "metadata": {
        "id": "w60z4hyJzdaW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if (save_trained_model):\n",
        "  model.save_pretrained(\"model-falcon-trained\")\n",
        "  !huggingface-cli login --token $HF_TOKEN\n",
        "  model.push_to_hub(\"rai-sandeep/model-falcon-trained\")"
      ],
      "metadata": {
        "id": "SDRHSSnZznmH"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8bK8VfO33_WI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prompt_and_generate():\n",
        "\n",
        "  doc_type = input(\"What type of document do you want to generate? (Enter White Paper or Press Release)\\n\")\n",
        "  topic = input(f\"On what topic do you want to generate the {doc_type}?\\n\")\n",
        "  keywords = input(f\"Enter any keywords that should be part of the {doc_type} in comma separated format. If none, press Enter.\\n\")\n",
        "  content_to_use = input(f\"Enter any content that should be used for the {doc_type}. If none, press Enter.\\n\")\n",
        "\n",
        "  doc_content=\"\"\n",
        "  doc_parts=[\"Abstract\",\"Introduction\",\"Problem Statement\",\"Methodology\",\"Findings and Analysis\",\"Recommendations\",\"Conclusion\"]\n",
        "\n",
        "  for doc_part in doc_parts:\n",
        "    prompt = f\"Generate a {doc_type} {doc_part} on {topic}.\"\n",
        "    if keywords.strip() != \"\":\n",
        "      prompt += f\"\\nInclude the following keywords: {keywords}.\"\n",
        "    if content_to_use.strip() != \"\":\n",
        "      prompt += f\"\\nHere is some context about {topic}: {content_to_use}.\\n\"\n",
        "\n",
        "    encoding = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda:0\")\n",
        "    output = model.generate(input_ids=encoding.input_ids, attention_mask=encoding.attention_mask, max_new_tokens=max_tok, do_sample=True, temperature=tempre, eos_token_id=tokenizer.eos_token_id, top_k = 0)\n",
        "\n",
        "    temp_content=tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    temp_content=temp_content.replace(prompt, \"\")\n",
        "    doc_content+=f\"\\n## {doc_part}  \\n{temp_content}  \\n\"\n",
        "\n",
        "  print(doc_content)\n",
        "\n",
        "  f = open(topic.replace(\" \", \"-\")+\".md\", \"w\")\n",
        "  f.write(doc_content)\n",
        "  f.close()"
      ],
      "metadata": {
        "id": "rFjXfYivrnGD"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prompt_and_generate()"
      ],
      "metadata": {
        "id": "79gmk3y1v6WK"
      },
      "execution_count": 19,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "396fe99cd3e84daba422d49bf1fbe0cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1f72368c28b6497e8276e5c2bca78cb7",
              "IPY_MODEL_8d008b6a6c1a4755a6a2f69e03f8b2d3",
              "IPY_MODEL_a172ae0048564dd2808d022fb8deae0f"
            ],
            "layout": "IPY_MODEL_07af99603a1342e186a61ae09c49788f"
          }
        },
        "1f72368c28b6497e8276e5c2bca78cb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_842b0a6ea0d14a48b926c515cf637d3e",
            "placeholder": "​",
            "style": "IPY_MODEL_074cd337f7ad49cdb3ae176e5b03bed5",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "8d008b6a6c1a4755a6a2f69e03f8b2d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9f44c4bb2874edaa398287551adeb5f",
            "max": 15,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0e3deb2ad353439e99134a7870832bee",
            "value": 15
          }
        },
        "a172ae0048564dd2808d022fb8deae0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e1b23a13eeb47d7bb52a518d88504ef",
            "placeholder": "​",
            "style": "IPY_MODEL_4e5b51a62fb04d6ba25e93dc0cb88dcc",
            "value": " 15/15 [02:30&lt;00:00,  8.32s/it]"
          }
        },
        "07af99603a1342e186a61ae09c49788f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "842b0a6ea0d14a48b926c515cf637d3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "074cd337f7ad49cdb3ae176e5b03bed5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9f44c4bb2874edaa398287551adeb5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e3deb2ad353439e99134a7870832bee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2e1b23a13eeb47d7bb52a518d88504ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e5b51a62fb04d6ba25e93dc0cb88dcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "06fe9ac9bbb045b998866426e0141987": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a532f9e0c9d5472fb3fe773bd3c3e2c1",
              "IPY_MODEL_2bead1cf44df4e9a9cc1420ff5e67c71",
              "IPY_MODEL_811097cda5e0455ba16823b8ba20322d"
            ],
            "layout": "IPY_MODEL_0994fe00d5d64b83b8a49644b4e53444"
          }
        },
        "a532f9e0c9d5472fb3fe773bd3c3e2c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09668ef7b79c46e9990377ca874628ad",
            "placeholder": "​",
            "style": "IPY_MODEL_f1d0e6d8c4264742a40030b03e5a067b",
            "value": "100%"
          }
        },
        "2bead1cf44df4e9a9cc1420ff5e67c71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_463307190d654217a0c2ecdaedf1cc25",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2ebf4fdb2c6c4c4fae4154732ce5bccc",
            "value": 1
          }
        },
        "811097cda5e0455ba16823b8ba20322d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d138e676ba244bfd9b092c58ef5301a9",
            "placeholder": "​",
            "style": "IPY_MODEL_c985d7e57d6a4360a4ac21eabb63aaf7",
            "value": " 1/1 [00:00&lt;00:00, 29.84it/s]"
          }
        },
        "0994fe00d5d64b83b8a49644b4e53444": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09668ef7b79c46e9990377ca874628ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1d0e6d8c4264742a40030b03e5a067b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "463307190d654217a0c2ecdaedf1cc25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ebf4fdb2c6c4c4fae4154732ce5bccc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d138e676ba244bfd9b092c58ef5301a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c985d7e57d6a4360a4ac21eabb63aaf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}